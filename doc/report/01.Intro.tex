Despite of the extraordinary performance with regard to the optimizations that
compilers (e.g. ICC, Clang/LLVM, gcc) may be able to do all over programs, they 
also
show limitations when it comes to vectorization. There are cases where either
they may not vectorize the code at all or even deliver worse performance than a
sequential version of it. This is a common scenario when the region of interest
in the code to vectorize is not regular. We may define the regularity of a code
as the presence of patterns whose accesses to the elements (e.g.
multi-dimensional arrays) are performed in a sequential and contiguous manner,
e.g. map operations. On the other hand, reductions are a type of operations
that, by nature,
do not fully exploit the capacity of vector operands. Current data placement or
packing techniques are meant just for loading and storing data from or to
memory, without performing any other logic than that. Potential improvements
regarding the vector occupancy by complex and smart packing techniques may lead
to major gains in performance. Picture the following example: within the same
loop we have two different and contiguous reductions. This is a common pattern
that can be found after the fusion of different loops, for instance, in codes
that perform convolutions. Assuming a vector size of four elements, a smart way
of computing this code is by

% Different ISA
In an orthogonal dimension, the quality of SIMD code is affected by the 
knowledge of the architecture where it is being compiled. Nevertheless, some 
information regarding the SIMD instructions performance may be missing or 
non-disclosed by the manufacturer. This information can be used to determine 
whether a vector operation is detrimental or not, i.e. for building a cost 
model. There may be architectures using the same ISA and, therefore, where the 
vectorization can be done using exactly the same instructions, but because of 
their architectural designs the performance may be different, leading to 
different approaches on each case. Thus, the only manner of disclosing this 
information is by reverse-engineering each architecture. This process is 
tedious and complex since there are many different instructions whose 
performance may be also vary depending on the packing of the data they use.


MACVETH is a source-to-source compiler which targets the vectorization of C/C++
codes. Thus, the input of this compiler is a non vectorized C/C++ code and the
output will be a SIMD-fashion C/C++ code (see Figure~\ref{fig:MACVETHarch}).
The name of the compiler stands for Multi-dimensional Array C-compiler for
VEctorizating Tensors for HPC applications. Besides, Macbeth, tragedy
written by William Shakespeare, represents the detrimental effects of human's
narcissism and vanity when looking for the power for its own benefits. As
opposed, MACVETH is composed by a set different layers and intermediate
representations that seek for the common purpose of improving performance. Last
but not least, the first and last letter of the acronym stand for the name of
the main author (Marcos Horro).

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/MACVETH.pdf}
	\caption{High-level picture of the MACVETH pipeline compiler.}
	\label{fig:MACVETHarch}
\end{figure}
